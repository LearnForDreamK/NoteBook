[TOC]



# ShardingSphere

> ShardingSphere官方文档 : https://shardingsphere.apache.org/document/current/cn/overview/
>
> 官方中文用例：https://github.com/apache/shardingsphere/blob/master/examples/README_ZH.md
>
> 分布式事务：https://zhuanlan.zhihu.com/p/183753774

最近看完了数科开发的ShardingSphere的官方文档，感觉收获很大，接触到了很多没接触的想法。总结记录一下怕以后忘了。 ElasticJob准备之后也总结一下。（完善中。。。。。。）

## 概念和功能

### 1.数据分片

之前申请弹性数据库时，需要申请多少分片，不明白是MySQL分片到底是啥意思，觉得MySQL只有主从，多主多从这种，看完文档后清晰了许多。

> **尽量透明化分库分表所带来的影响，让使用方尽量像使用一个数据库一样使用水平分片之后的数据库集群，是 Apache ShardingSphere 数据分片模块的主要设计目标。**

#### 1）垂直分片

按业务进行拆分，观念是专库专用，拆分之后可能之前一个库中的一个表或多个表对应一个新库，但这种拆分一般需要对业务和架构进行调整，而且只能缓解压力，不能根治问题，不能解决单一表压力过大的问题。需要水平分片进一步处理。

#### 2）水平分片

不再根据业务逻辑分类，根据字段（1个或多个）和某种规则把数据分散到多个库和表中，每个分片只包含数据的一部分，

#### 3）问题

查询需要知道从哪些分片查，SQL分片后不一定能正常运行，分布式事务。

### 2.分布式事务

由多个事务组成的事务。

#### 1.普通事务

1）ACID

2）隔离级别

3）Redis事务

#### 2. 2PC

> 2PC（Two-phase commit protocol），中文叫二阶段提交。 **二阶段提交是一种强一致性设计**，2PC 引入一个事务协调者的角色来协调管理各参与者（也可称之为各本地资源）的提交和回滚，二阶段分别指的是准备（投票）和提交两个阶段。

##### 1）准备阶段

事务协调者发布命令，所有事务执行除提交外的全部任务，执行完成后回应一个ACK给协调者。

##### 2）提交阶段

事务协调者收到所有的ACK，让所有子事务执行提交操作，或者未收到所有ACK，让所有子事务执行回滚操作。

##### 3）其他情况

1）准备阶段子事务执行超时，其他事务全部回滚，事务判断为失败。
2）提交阶段某子事务回滚失败，会一直尝试回滚，否则其他在第一阶段准备的事务会一直阻塞。
3）提交阶段某子事务提交失败，会一直尝试提交，直到成功或人工介入。
4）存在单点故障问题（可以引入多点，单点挂了进行选举，选出新节点）。
5）极端条件下存在数据不一致问题（子事务节点也挂了的情况），协调者操作时，在子事务节点处留下操作日志，供故障恢复使用。



#### 3. 3PC

> 3PC 的出现是为了解决 2PC 的一些问题，相比于 2PC 它在**参与者中也引入了超时机制**，并且**新增了一个阶段**使得参与者可以利用这一个阶段统一各自的状态。

##### 1）准备阶段

协调者和所有子事务节点交互，判断子事务节点是否能执行任务。

##### 2）预提交阶段

协调者通知所有子事务节点，执行除提交外的所有任务。

##### 3）提交阶段

流程基本和2PC相同，不同的是子事务节点也加入了事务超时机制，一定时间没收到预提交命令就直接执行其他工作，一定时间没收到提交命令，则直接提交事务。 在协调者节点和子事务节点同时宕机的情况下还是会发生数据不一致问题。

协调者挂了以后，新协调者来的时候发现有一个参与者处于预提交或者提交阶段，那么表明已经经过了所有参与者的确认了，所以此时执行的就是提交命令。 但这时是可能出现不一致问题的，因为不知道挂了的参与者到底有没有提交数据。

#### 4.TCC

>  **TCC 是业务层面的分布式事务**，TCC 指的是`Try - Confirm - Cancel`。

##### 1.Try

业务端向管理端发起事务，同时向所有子事务发起try请求，进行资源的预留和锁定。

##### 2.confirm

子事务端开始执行任务。

##### 3.cancel

把预留状态做的操作取消，即取消资源的预留和锁定。

##### 4.大概流程

发起事务（调用者）、调用try（调用者）、拿到try返回结果（调用者）、提交或回滚（调用者）、根据提交或回滚进行try或cancel操作（管理者）

##### 5.其他

1）对业务侵入大，开发量大。
2）撤销或确认请求可能需要重试，需要保证幂等。
3）可以跨数据库，跨不同的业务系统来实现事务。

#### 5.本地消息表

> https://juejin.cn/post/6844904041659498509

在本地维护一张存放本地消息的表，在执行本地事务时，在本地事务中加入一个操作，插入一条消息到本地表中，这条消息维护一个状态， 保证本地表操作和本地事务操作的强一致性。 然后再执行其他子事务，下一个事务成功执行后，发出一个消息设置上一个事务处的本地消息表状态为成功。 同时需要在业务处维护定时器，监控哪些任务未被成功执行，保证成功执行，这时可能会出现重复消费的情况，需要保证操作的幂等性。

拥有最终一致性。

#### 6.消息事务

##### 1.过程

1.首先发送半消息，这个消息对消费者不可见。
2.本地执行完事务后，如果成功则向mq发送commit消息，失败则发送回滚消息，回滚消息会删除半消息。
3.订阅方收到消息后进行消费，执行完事务后进行完成消息消费步骤。



#### 7.最大努力通知

本地消息表和消息事务都可以算最大努力通知了，本地消息表如果某个消息状态一直无法改变，则会人工介入或者丢弃消息，消息事务也一样，如果消息在MQ中一直无法被消费者消费，则会不断重试直到进入死信队列。 是一种柔性事务的思想，尽最大努力保证事务的一致性。



#### 8.Seata

> 提供AT TCC SAGA XA事务模式。
>
> https://seata.io/zh-cn/docs/overview/what-is-seata.html



### 3.读写分离

> 目标：**透明化读写分离所带来的影响，让使用方尽量像使用一个数据库一样使用主从数据库集群，是ShardingSphere读写分离模块的主要设计目标。**

1）MySQL主从架构，主节点负责增删改，从节点负责读，避免因为修改而产生的行锁影响读的效率。

2）根据SQL语句解析将操作分别路由到主库和从库。

3）通过负载均衡策略，将请求路由至不同的从库。

### 4.分布式治理

### 5.弹性伸缩

> 目标：支持各类用户自定义的分片策略，减少用户在数据伸缩及迁移时的重复工作及业务影响，提供一站式的通用弹性伸缩解决方案，不影响原来的数据，是 Apache ShardingSphere 弹性伸缩的主要设计目标。

原理是使用两个数据库集群，伸缩完成后切换的方式实现。主要分为4个步骤：

1）准备阶段
检查数据源，统计存量数据，记录日志位点，拆分任务。
2）存量迁移阶段
迁移每个数据节点的存量数据。汇总迁移进度。直接使用JDBC查询数据节点数据，然后使用新规则写入集群。
3）增量同步阶段
同步每一个数据源的增量数据，汇总增量数据的延迟。 可以通过订阅MySQL binlog日志进行解析，按配置的规则进行同步。（上次听部门内同事说也有通过增量MQ同步的方法）
4）配置切换阶段
设置旧库只读，确保增量数据同步完成，进行数据校验，切换配置，将业务导向新规则集群。

### 6.数据加密

> 目标：**根据业界对加密的需求及业务改造痛点，提供了一套完整、安全、透明化、低改造成本的数据加密整合解决方案，是Apache ShardingSphere 数据加密模块的主要设计目标。**

**Apache ShardingSphere 将面向用户的逻辑列与面向底层数据库的明文列和密文列进行了列名以及数据的加密映射转换。**

一般数据库中保存明文列和密文列，名文列主要用于条件查询用，在执行SQL时，ShardingSphere根据映射规则和加密规则，把逻辑列修改为明文列和密文列插入数据库中。 

我理解为主表保存加密后的字段，ShardingSphere通过逻辑列和改写SQL屏蔽加密和用户操作之间的关系。针对逻辑列的增删改查操作的语句都会被改写，加密器加密解密数据。 一般表中最后不会保存明文数据。

#### 1）新项目处理

对于新项目，直接配置好逻辑字段和表加密字段的映射关系，不需要进行额外操作，配置好加密算法和映射规则，不需要保存明文字段。

#### 2）老项目处理

对于老项目，如果需要加密某字段，可以先配置逻辑字段和表中明文字段相同，然后再添加加密字段和对应加密算法，给增量数据添加明文和密文两个字段的数据，然后通过配置，让查询不经过加密算法，直接通过明文查询，不影响原来服务的提供，此时对于存量数据，需要开发人员自己手动准备方案进行加密，然后等系统稳定后，修改设置，让查询也经过加密算法进行加密，最后的最后等系统很稳定后，可以对所有明文字段进行删除处理，修改配置，让逻辑字段对应到密文字段。

#### 3）其他

1）可以通过实现接口自定义加密算法。
2）可以通过实现接口+加密因子实现同明文不同密文。

### 7.影子库压测

> 目标：Apache ShardingSphere 关注于全链路压测场景下，数据库层面的解决方案。 基于内核的 SQL 解析能力，以及可插拔平台架构，实现压测数据与生产数据的隔离，帮助应用自动路由，支持全链路压测，是 Apache ShardingSphere 影子数据库模块的主要设计目标。

在压测时，如果构建一个和生产环境类似的环境成本较高，所以使用全链路压测进行压测，即使用生产环境进行压测。

原理是解析SQL语句中的逻辑字段，这个逻辑字段在数据库是不存在的，在SQL解析时会移除该字段并根据映射配置信息进行路由，路由到对应影子库（生产数据库和影子库必须一一对应）。

### 8.Dist SQL

> 目标：**打破中间件和数据库之间的界限，让开发者像使用数据库一样使用 Apache ShardingSphere，是 DistSQL 的设计目标。**

### 9.可插拔架构

> 目标：**让开发者能够像使用积木一样定制属于自己的独特系统，是 Apache ShardingSphere 可插拔架构的设计目标。**

通过SPI机制进行扩展。

### 10.测试引擎

